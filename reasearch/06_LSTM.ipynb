{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xarray as xr\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input\n",
    "import os\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Vorbereitung von CSV-Daten (Konvertierung der 'dtm' Spalte in datetime-Format)\n",
    "def pre_csv(df):\n",
    "    df.dtm = pd.to_datetime(df.dtm)  # Konvertiert die 'dtm' Spalte in das Datumsformat\n",
    "    return df\n",
    "\n",
    "# Funktion zur Vorbereitung von DWD-Daten (Konvertierung und Bereinigung)\n",
    "def pre_dwd(df):\n",
    "    df = df.to_dataframe().reset_index().rename(columns={\"ref_datetime\": \"reference_time\", \"valid_datetime\": \"valid_time\"})\n",
    "    df.reference_time = df.reference_time.dt.tz_localize(\"UTC\")  # Lokalisierung der 'reference_time' auf UTC\n",
    "    df.valid_time = df.reference_time + df.valid_time * pd.Timedelta(1, \"h\")  # Berechnung von 'valid_time' basierend auf Stunden\n",
    "    return df\n",
    "\n",
    "# Platzhalter für zukünftige NCEP-Datenvorbereitung\n",
    "def pre_ncep(df):\n",
    "    return df\n",
    "\n",
    "# Öffnen und Vorbereiten mehrerer DWD-Datensätze (PES)\n",
    "df_pes_0 = pre_dwd(xr.open_dataset(\"data/dwd_icon_eu_pes10_20200920_20231027.nc\"))\n",
    "df_pes_1 = pre_dwd(xr.open_dataset(\"data/dwd_icon_eu_pes10_20231027_20240108.nc\"))\n",
    "df_pes_2 = pre_dwd(xr.open_dataset(\"data/dwd_icon_eu_pes10_20240108_20240129.nc\"))\n",
    "df_pes_3 = pre_dwd(xr.open_dataset(\"data/dwd_icon_eu_pes10_20240129_20240519.nc\"))\n",
    "\n",
    "# Zusammenführen, Sortieren und Bereinigen der PES-Daten\n",
    "df_pes = pd.concat([df_pes_0, df_pes_1, df_pes_2, df_pes_3]).sort_values([\"reference_time\", \"valid_time\"]).reset_index(drop=True)\n",
    "del df_pes_0, df_pes_1, df_pes_2, df_pes_3\n",
    "\n",
    "df_pes = df_pes.groupby([\"reference_time\", \"valid_time\"]).mean().reset_index().drop(columns=[\"point\", \"longitude\", \"latitude\"])\n",
    "\n",
    "# Interpolation auf 30-Minuten-Intervalle\n",
    "df_pes = df_pes.set_index(\"valid_time\").groupby([\"reference_time\"]).resample(\"30min\").interpolate(\"linear\").drop(columns=\"reference_time\").reset_index()\n",
    "\n",
    "# Gleicher Prozess für Hornsea-Daten\n",
    "df_hornsea_0 = pre_dwd(xr.open_dataset(\"data/dwd_icon_eu_hornsea_1_20200920_20231027.nc\"))\n",
    "df_hornsea_1 = pre_dwd(xr.open_dataset(\"data/dwd_icon_eu_hornsea_1_20231027_20240108.nc\"))\n",
    "df_hornsea_2 = pre_dwd(xr.open_dataset(\"data/dwd_icon_eu_hornsea_1_20240108_20240129.nc\"))\n",
    "df_hornsea_3 = pre_dwd(xr.open_dataset(\"data/dwd_icon_eu_hornsea_1_20240129_20240519.nc\"))\n",
    "\n",
    "df_hornsea = pd.concat([df_hornsea_0, df_hornsea_1, df_hornsea_2, df_hornsea_3]).sort_values([\"reference_time\", \"valid_time\"]).reset_index(drop=True)\n",
    "del df_hornsea_0, df_hornsea_1, df_hornsea_2, df_hornsea_3\n",
    "\n",
    "df_hornsea = df_hornsea.groupby([\"reference_time\", \"valid_time\"]).mean().reset_index().drop(columns=[\"longitude\", \"latitude\"])\n",
    "\n",
    "df_hornsea = df_hornsea.set_index(\"valid_time\").groupby([\"reference_time\"]).resample(\"30min\").interpolate(\"linear\").drop(columns=\"reference_time\").reset_index()\n",
    "\n",
    "# Einlesen und Vorbereiten von CSV-Daten\n",
    "df_0 = pre_csv(pd.read_csv(\"data/Energy_Data_20200920_20240118.csv\"))\n",
    "df_1 = pre_csv(pd.read_csv(\"data/Energy_Data_20240119_20240519.csv\"))\n",
    "\n",
    "# Zusammenführen und Sortieren der CSV-Daten\n",
    "df = pd.concat([df_0, df_1]).sort_values([\"dtm\"]).reset_index(drop=True)\n",
    "del df_0, df_1\n",
    "\n",
    "# Berechnen von Wind- und Solar-MWh-Krediten\n",
    "df[\"Wind_MWh_credit\"] = 0.5 * df[\"Wind_MW\"] - df[\"boa_MWh\"]\n",
    "df[\"Solar_MWh_credit\"] = 0.5 * df[\"Solar_MW\"]\n",
    "\n",
    "# Zusammenführen der PES- und Hornsea-Daten\n",
    "df_full = pd.merge(df_pes, df_hornsea, on=[\"reference_time\", \"valid_time\"])\n",
    "\n",
    "# Zusammenführen mit CSV-Daten basierend auf der 'valid_time'\n",
    "df_full = df_full.merge(df[[\"dtm\", \"Wind_MWh_credit\", \"Solar_MWh_credit\"]], left_on=\"valid_time\", right_on=\"dtm\", how=\"left\")\n",
    "\n",
    "# Berechnung zusätzlicher Spalten\n",
    "df_full[\"forcast_hours\"] = (df_full.valid_time - df_full.reference_time) / pd.Timedelta(1, \"h\")\n",
    "df_full[\"year\"] = df_full.valid_time.dt.year\n",
    "df_full[\"month\"] = df_full.valid_time.dt.month\n",
    "df_full[\"day\"] = df_full.valid_time.dt.day\n",
    "df_full[\"hour\"] = df_full.valid_time.dt.hour\n",
    "\n",
    "# Berechnung der Gesamterzeugung (MWh)\n",
    "df_full[\"total_generation_MWh\"] = df_full[\"Wind_MWh_credit\"] + df_full[\"Solar_MWh_credit\"]\n",
    "\n",
    "df_train = df_full.loc[df_full.reference_time < \"2023-05-20\"]\n",
    "df_test = df_full.loc[df_full.reference_time >= \"2023-05-20\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351137, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainiere Modell mit 64 32 LSTM-Einheiten, Epochs: 5, Batch Size: 2048, regularizers_faktor: 0.4, Dropout Rate 1: 0.3, Dropout Rate 2: 0.1\n",
      "Keine GPU gefunden. Das Modell wird auf der CPU trainiert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset['Model_1_q50'] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9344/9344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset[f\"Model_1_q{qu}\"] = df_train_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset[f\"Model_1_q{qu}\"] = df_train_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset[f\"Model_1_q{qu}\"] = df_train_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset[f\"Model_1_q{qu}\"] = df_train_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset[f\"Model_1_q{qu}\"] = df_train_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset[f\"Model_1_q{qu}\"] = df_train_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset[f\"Model_1_q{qu}\"] = df_train_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset[f\"Model_1_q{qu}\"] = df_train_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset['Model_1_q50'] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9344/9344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset[f\"Model_1_q{qu}\"] = df_test_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset[f\"Model_1_q{qu}\"] = df_test_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset[f\"Model_1_q{qu}\"] = df_test_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset[f\"Model_1_q{qu}\"] = df_test_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset[f\"Model_1_q{qu}\"] = df_test_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset[f\"Model_1_q{qu}\"] = df_test_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset[f\"Model_1_q{qu}\"] = df_test_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset[f\"Model_1_q{qu}\"] = df_test_subset['Model_1_q50'] * (qu / 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Kombination: Epochs: 5.0, Batch Size: 2048.0, regularizers_faktor: 0.4, LSTM Units 1: 64.0,LSTM Units 2: 32.0, Dropout Rate 1: 0.3, Dropout Rate 2: 0.1, Pinball Score Test: 190.5070803122052\n",
      "Trainiere Modell mit 64 32 LSTM-Einheiten, Epochs: 5, Batch Size: 2048, regularizers_faktor: 0.1, Dropout Rate 1: 0.3, Dropout Rate 2: 0.1\n",
      "Keine GPU gefunden. Das Modell wird auf der CPU trainiert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset['Model_1_q50'] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9344/9344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_subset[f\"Model_1_q{qu}\"] = df_train_subset['Model_1_q50'] * (qu / 100)\n",
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset['Model_1_q50'] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9344/9344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step\n",
      "Beste Kombination: Epochs: 5.0, Batch Size: 2048.0, regularizers_faktor: 0.1, LSTM Units 1: 64.0,LSTM Units 2: 32.0, Dropout Rate 1: 0.3, Dropout Rate 2: 0.1, Pinball Score Test: 190.50482848337572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael Jäckle\\AppData\\Local\\Temp\\ipykernel_33676\\3586486559.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_subset[f\"Model_1_q{qu}\"] = df_test_subset['Model_1_q50'] * (qu / 100)\n"
     ]
    }
   ],
   "source": [
    "def pinball(y, q, alpha):\n",
    "    return (y - q) * (alpha - (y < q))\n",
    "\n",
    "def pinball_score(df, model_idx):\n",
    "    score = []\n",
    "    for qu in range(10, 100, 10):\n",
    "        y_true = df['total_generation_MWh']\n",
    "        y_pred = df[f'Model_{model_idx}_q{qu}']\n",
    "        score.append(pinball(y_true, y_pred, qu / 100).mean())\n",
    "    return score\n",
    "\n",
    "# Annahme: df_full ist bereits geladen und enthält die Spalte 'reference_time'\n",
    "df_train = df_full.loc[df_full.reference_time < \"2023-05-20\"]\n",
    "df_test = df_full.loc[df_full.reference_time >= \"2023-05-20\"]\n",
    "\n",
    "data_sizes = [299008]#, 200000, 300000]  # Hier kannst du weitere Größen hinzufügen\n",
    "regularizers_faktor = [0.4,  0.1, ]\n",
    "dropout_rates_1 = [0.3, ]\n",
    "dropout_rates_2 = [0.1, ]\n",
    "epochs_options = [5, ]\n",
    "batch_sizes = [2048]  #1024\n",
    "sequence_lengths = [12]\n",
    "lstm_units_1 = [64]  \n",
    "lstm_units_2 = [32] \n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%d_%H-%M-%S\")\n",
    "results_file_name = f\"data/results_{current_time}.csv\"\n",
    "\n",
    "# Sicherstellen, dass das Verzeichnis existiert\n",
    "os.makedirs(os.path.dirname(results_file_name), exist_ok=True)\n",
    "\n",
    "with open(results_file_name, 'w') as f:\n",
    "    f.write('Epochs,Batch_Size,Sequence_Length,Dropout_Rate_1,Dropout_Rate_2,Regularizers_Faktor,LSTM_Units_1,LSTM_Units_2,Data_Size,Pinball_Score_Train,Pinball_Score_Test\\n')\n",
    "\n",
    "for data_size in data_sizes:\n",
    "    df_train_subset = df_train.head(data_size)\n",
    "    df_test_subset = df_test.head(data_size)\n",
    "\n",
    "    features = ['CloudCover', 'SolarDownwardRadiation', 'Temperature_x',\n",
    "                'RelativeHumidity', 'Temperature_y', 'WindDirection',\n",
    "                'WindSpeed', 'forcast_hours', 'year', 'month', 'day', 'hour']\n",
    "    target = 'total_generation_MWh'\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_train_data = scaler.fit_transform(df_train_subset[features + [target]])\n",
    "\n",
    "    # Sequenzen für Trainingsdaten erstellen\n",
    "    X_train, y_train = [], []\n",
    "    for i in range(sequence_lengths[0], len(scaled_train_data)):\n",
    "        X_train.append(scaled_train_data[i-sequence_lengths[0]:i, :-1])\n",
    "        y_train.append(scaled_train_data[i, -1])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    scaled_test_data = scaler.transform(df_test_subset[features + [target]])\n",
    "\n",
    "    # Sequenzen für Testdaten erstellen\n",
    "    X_test, y_test = [], []\n",
    "    for i in range(sequence_lengths[0], len(scaled_test_data)):\n",
    "        X_test.append(scaled_test_data[i-sequence_lengths[0]:i, :-1])\n",
    "        y_test.append(scaled_test_data[i, -1])\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "    # Parameterkombinationen definieren, einschließlich der LSTM-Einheiten\n",
    "    \n",
    "    param_combinations = list(product(\n",
    "        epochs_options,\n",
    "        batch_sizes,\n",
    "        dropout_rates_1,\n",
    "        dropout_rates_2,\n",
    "        regularizers_faktor,\n",
    "        lstm_units_1,\n",
    "        lstm_units_2  \n",
    "    ))\n",
    "\n",
    "    for epochs, batch_size, dropout_rate_1, dropout_rate_2, reg_factor, units_1, units_2 in param_combinations:\n",
    "        print(f\"Trainiere Modell mit {units_1} {units_2} LSTM-Einheiten, Epochs: {epochs}, Batch Size: {batch_size}, \"\n",
    "            f\"regularizers_faktor: {reg_factor}, Dropout Rate 1: {dropout_rate_1}, Dropout Rate 2: {dropout_rate_2}\")\n",
    "\n",
    "        model = Sequential()\n",
    "        # Hier fügen wir den Input-Layer hinzu\n",
    "        model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        \n",
    "        model.add(LSTM(units_1, return_sequences=True,\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate_1))\n",
    "        model.add(LSTM(units_2, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate_2))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        if tf.config.list_physical_devices('GPU'):\n",
    "            print(\"GPU gefunden. Das Modell wird auf der GPU trainiert.\")\n",
    "        else:\n",
    "            print(\"Keine GPU gefunden. Das Modell wird auf der CPU trainiert.\")\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2,\n",
    "                  callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        df_train_subset['Model_1_q50'] = np.nan\n",
    "        train_predictions = model.predict(X_train)\n",
    "        df_train_subset.loc[df_train_subset.index[-len(train_predictions):], 'Model_1_q50'] = train_predictions.flatten()\n",
    "\n",
    "        for qu in range(10, 100, 10):\n",
    "            df_train_subset[f\"Model_1_q{qu}\"] = df_train_subset['Model_1_q50'] * (qu / 100)\n",
    "\n",
    "        train_score = pinball_score(df_train_subset, 1)\n",
    "        overall_pinball_score_train = sum(train_score) / len(train_score)\n",
    "\n",
    "        df_test_subset['Model_1_q50'] = np.nan\n",
    "        test_predictions = model.predict(X_test)\n",
    "        df_test_subset.loc[df_test_subset.index[-len(test_predictions):], 'Model_1_q50'] = test_predictions.flatten()\n",
    "\n",
    "        for qu in range(10, 100, 10):\n",
    "            df_test_subset[f\"Model_1_q{qu}\"] = df_test_subset['Model_1_q50'] * (qu / 100)\n",
    "\n",
    "        test_score = pinball_score(df_test_subset, 1)\n",
    "        overall_pinball_score_test = sum(test_score) / len(test_score)\n",
    "\n",
    "        # Ergebnisse in die CSV schreiben, einschließlich der LSTM-Einheiten\n",
    "        with open(results_file_name, 'a') as f:\n",
    "            f.write(f\"{epochs},{batch_size},{sequence_lengths[0]},{dropout_rate_1},{dropout_rate_2},{reg_factor},{units_1},{units_2},{data_size},{overall_pinball_score_train},{overall_pinball_score_test}\\n\")\n",
    "\n",
    "        results_df = pd.read_csv(results_file_name)\n",
    "        best_result = results_df.loc[results_df['Pinball_Score_Test'].idxmin()]\n",
    "        print(f\"Beste Kombination: Epochs: {best_result['Epochs']}, Batch Size: {best_result['Batch_Size']}, \"\n",
    "              f\"regularizers_faktor: {best_result['Regularizers_Faktor']}, LSTM Units 1: {best_result['LSTM_Units_1']},LSTM Units 2: {best_result['LSTM_Units_2']}, \"\n",
    "              f\"Dropout Rate 1: {best_result['Dropout_Rate_1']}, Dropout Rate 2: {best_result['Dropout_Rate_2']}, \"\n",
    "              f\"Pinball Score Test: {best_result['Pinball_Score_Test']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
