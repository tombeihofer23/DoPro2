{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training config entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_models_path: Path\n",
    "    training_data_path: Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update config manager class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dopro2_HEFTcom_challenge.constants import PARAMS_FILE_PATH, CONFIG_FILE_PATH\n",
    "import yaml\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    \"\"\"Class to manage all configurations.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Path = CONFIG_FILE_PATH,\n",
    "        params_filepath: Path = PARAMS_FILE_PATH\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for ConfigurationManager Class.\n",
    "        Creates artifacts folder.\n",
    "\n",
    "        :param config_filepath: Path to config.yaml file\n",
    "        :param params_filepath: Path to params.yaml file\n",
    "\n",
    "        \"\"\"\n",
    "        with config_filepath.open(\"r\") as f:\n",
    "            self.config: dict = yaml.safe_load(f)\n",
    "\n",
    "        with params_filepath.open(\"r\") as f:\n",
    "            self.params: dict = yaml.safe_load(f)\n",
    "\n",
    "        os.makedirs(self.config[\"artifacts_root\"], exist_ok=True)\n",
    "        logger.info(\"created directory at: {}\", self.config[\"artifacts_root\"])\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        \"\"\"\n",
    "        Get all config params and create folder in artifacts dir.\n",
    "        \n",
    "        :return: values from config.yaml\n",
    "        :rtype: TrainingConfig\n",
    "        \"\"\"\n",
    "        config = self.config[\"training\"]\n",
    "        params = self.params\n",
    "\n",
    "        os.makedirs(config[\"root_dir\"], exist_ok=True)\n",
    "        logger.info(\"created directory at: {}\", config[\"root_dir\"])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=config[\"root_dir\"],\n",
    "            trained_models_path=config[\"trained_models_path\"],\n",
    "            training_data_path=config[\"training_data_path\"]\n",
    "        )\n",
    "\n",
    "        return training_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create training component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.iolib.smpickle import load_pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    \"\"\"Class to performe the model training.\"\"\"\n",
    "\n",
    "    def __init__(self, config: TrainingConfig) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for Training class.\n",
    "\n",
    "        :param config: config values from config.yaml\n",
    "        \"\"\"\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "    @staticmethod\n",
    "    def save_models(forecast_models: dict, path: Path) -> None:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        logger.info(\"created directory at: {}\", path)\n",
    "\n",
    "        for quantile in range(10,100,10):\n",
    "            forecast_models[f\"q{quantile}\"].save(f\"{path}/model_q{quantile}.pickle\")\n",
    "        logger.info(\"saved all models in at {}\", path)\n",
    "\n",
    "    def train(self) -> None:\n",
    "        logger.info(\"Loading trainind data from {}\", self.config.training_data_path)\n",
    "        training_data = pd.read_parquet(self.config.training_data_path)\n",
    "        model = smf.quantreg(\n",
    "            formula='total_generation_MWh ~ bs(SolarDownwardRadiation,df=5) + bs(WindSpeed,df=8)',\n",
    "            data=training_data\n",
    "        )\n",
    "\n",
    "        logger.info(\"Start model training\")\n",
    "        forecast_models = dict()\n",
    "        for quantile in range(10,100,10):\n",
    "            forecast_models[f\"q{quantile}\"] = model.fit(q=quantile/100,max_iter=2500)\n",
    "            training_data[f\"q{quantile}\"] = forecast_models[f\"q{quantile}\"].predict(training_data)\n",
    "            training_data.loc[training_data[f\"q{quantile}\"] < 0, f\"q{quantile}\"] = 0\n",
    "        logger.info(\"Model trained\")\n",
    "\n",
    "        self.save_models(forecast_models, self.config.trained_models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-10 17:54:40.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mcreated directory at: artifacts\u001b[0m\n",
      "\u001b[32m2024-10-10 17:54:40.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_training_config\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mcreated directory at: artifacts/training\u001b[0m\n",
      "\u001b[32m2024-10-10 17:54:40.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mLoading trainind data from artifacts/prepared_data/model_data.parquet\u001b[0m\n",
      "\u001b[32m2024-10-10 17:54:42.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mStart model training\u001b[0m\n",
      "c:\\Tom\\HKA\\7_Semester\\Domänenprojekt_2\\DoPro\\.env\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (2500) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "c:\\Tom\\HKA\\7_Semester\\Domänenprojekt_2\\DoPro\\.env\\Lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (2500) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "\u001b[32m2024-10-10 18:07:59.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mModel trained\u001b[0m\n",
      "\u001b[32m2024-10-10 18:07:59.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_models\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mcreated directory at: artifacts/training/models\u001b[0m\n",
      "\u001b[32m2024-10-10 18:08:19.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_models\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1msaved all models in at artifacts/training/models\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
